---
tags: []
published: true
title: La gestion des incidents @Yousign
excerpt: Le nombre d‚Äôincidents sur une production informatique n‚Äôest jamais de 0,
  comme vous en doutez, c‚Äôest une composante essentielle de nos m√©tiers, c‚Äôest pourquoi
  on va s‚Äôefforcer de vous pr√©senter notre nouvelle gestion des incidents.
coverImage: https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/13-Gestion
  des incidents@2x.png
date: 2022-02-04T10:15:00Z
authors:
- _data/authors/Daniel Castronovo.md

---
## Qu‚Äôest ce qu‚Äôun incident ?

C‚Äôest un **√©v√©nement** qui arrive quand on ne s‚Äôy attend pas en r√®gle g√©n√©raleüòÇ  et qui cause une d√©gradation partielle ou totale du service, dans notre cas li√© √† un contexte de signature √©lectronique certifi√© [EIDAS](https://www.ssi.gouv.fr/administration/reglementation/confiance-numerique/le-reglement-eidas/) qui poss√®de plus de 8000 clients aux quatre coins du monde.

Le nombre d‚Äôincidents sur une production informatique n‚Äôest jamais de 0, comme vous en doutez, c‚Äôest une composante essentielle de nos m√©tiers, c‚Äôest pourquoi on va s‚Äôefforcer de vous pr√©senter notre nouvelle gestion des incidents.

### Je vais vous donner un exemple parlant

Imaginez que vous √™tes en train d‚Äôacheter votre super appartement vue mer.

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Untitled1.png)

Vous √™tes chez votre banquier, et vous vous appr√™tez √† signer votre cr√©dit pour 20 ans, quand vous voyez cette barre de chargement rester bloqu√©e ?

![](https://media.giphy.com/media/KG4PMQ0jyimywxNt8i/giphy.gif "Barre de chargement")

On se bat quotidiennement pour ne pas que √ßa vous arrive üòé

Vous comprenez pourquoi nous mettons autant d‚Äô√©nergie dans ce processus √† pr√©sent ?

## Qu‚Äôest ce que la gestion des incidents ?

C‚Äôest un des processus [**ITIL**](https://fr.wikipedia.org/wiki/Gestion_des_incidents) phare :

> La gestion des incidents est le processus de gestion des interruptions du service informatique et la restauration des services conform√©ment aux accords de prestation de services (SLA).  
> La gestion des incidents s‚Äô√©tend d‚Äôun utilisateur final ou une alerte de monitoring signalant un probl√®me jusqu‚Äôau membre d‚Äôune √©quipe du service d‚Äôassistance r√©solvant ce probl√®me.

Nous allons dans cet article vous expliquer ce que √ßa veut dire chez Yousign.

## Comment faisait-on jusqu‚Äôa pr√©sent ?

Les SRE ont un r√¥le transverse chez Yousign, ils sont garants du bon fonctionnement g√©n√©ral de la plateforme et du bon respect des standards de production.

Que ce soit pour une probl√©matique d‚Äôinfrastructure, de s√©curit√©, de performance ou applicative, les SRE intervenaient.

Contributeurs majeurs d√®s lors qu‚Äôil y a du refactoring, des migrations, etc.

## Illustration de l‚Äôancien workflow

On avait r√©guli√®rement sur Discord une douzaine de personnes lors d'un incident.

Cette raison est historique car actuellement nous sommes en train de scaler et donc mieux nous organiser.

Cela s‚Äôexpliquait par :

* La taille des √©quipes r√©duite
* Les scopes pas forc√©ment tr√®s clairement d√©finis

Ce qui se traduisait par :

1Ô∏è‚É£ On voit l'alerte sur Slack, on l‚Äôacquitte sur notre alert bot OpsGenie

2Ô∏è‚É£ On d√©clenche une discussion en vocal sur Discord

![Panique](https://media.giphy.com/media/l41YgPwuB0OXkRccM/giphy.gif)

3Ô∏è‚É£ On discute de l'incident tous en m√™me temps sur Discord (SRE, Devs, managers)

4Ô∏è‚É£ On donne tout un chacun notre avis, et quelque fois on discute m√™me de la pluie et du beau temps ‚õÖ

**R√©sultat** : c‚Äô√©tait d'un brouhaha incessant üß†

## Pourquoi avoir op√©r√© ce changement ?

* Augmenter l‚Äôownership des diff√©rents acteurs de la cha√Æne de cr√©ation de valeur :
  * Developpeur
  * QA
  * Data
  * CISO
  * Etc.
* Comme nous sommes en phase de scale, on aspire a √™tre plus performants, pertinents quant au fait de traiter nos incidents et surtout √™tre plus rapides pour les d√©celer, les corriger, en soit r√©duire le MTTR Mean Time To Resolve)
* Gagner en reporting pour obtenir des statistiques d√©taill√©es sur le nombre d‚Äôincidents / squads, ainsi que les d√©lais de traitement, etc.

## Comment ?

Nous avons **taggu√©** chaque alerte dans les outils suivants :

* Graylog (centralisation des logs)
* Redash (alerting SQL)
* Datadog (plateforme d‚Äôobservabilit√©)
* Youmonit (outil interne permettant d‚Äôobserver les queues RabbitMQ)
* StatusCake (synthetics monitoring)

Notre convention de nommage contient :

* Le nom de l‚Äôapplication
* La squad qui est owner de l‚Äôalerte
* La description de l‚Äôalerte

### Exemple d‚Äôune alerte

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Exemple d'incident.png)

## Proc√©dure d‚Äôexploitation

Chaque alerte contient une **proc√©dure d‚Äôexploitation**, ce qui permet √† tous de savoir a quoi l‚Äôalerte fait r√©f√©rence en termes de crit√®res de d√©clenchement, ainsi que la proc√©dure de r√©solution, mais √©galement le temps n√©cessaire th√©orique.

Autre avantage, offrir aux nouveaux onboard√©s un support leur permettant de prendre connaissance des diff√©rentes typologies d‚Äôalertes et d‚Äôincidents.

## Cr√©ation d‚Äôune base de donn√©es Notion

Chaque alerte poss√®de une page Notion, qui elle-m√™me est r√©f√©renc√©e sur une base de donn√©es Notion.

Ceci permet une recherche facilit√©e, et une meilleure lisibilit√© des alertes en les groupant suivant certains crit√®res.

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Database Notion alerte.png)

## Delivery

Chaque feature **doit** partir en production avec des alertes pertinentes, test√©es auparavant et valid√©es par l‚Äô√©quipe SRE, dans le cadre du **production readiness** qui explicite les attendus de production.

## Workflow

### Incident de production

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Gestion des incidents avec Opsgenie(3).jpeg)

## Post-mortem

Chaque incident critique donne lieu √† la cr√©ation d‚Äôun post-mortem.

Pour les incidents **majeurs** nous publions une version simplifi√©e de celui-ci sur notre plateforme **StatusPage**, ce qui permet √† nos clients de conna√Ætre les raisons du dysfonctionnement et les actions que nous avons entreprises pour mitiger l‚Äôincident.

## Observabilit√©

Pour √™tre efficace sur la gestion d‚Äôincident, il est primordial d‚Äô√™tre efficace sur ce que l‚Äôon observe. Sans √ßa on peut tr√®s vite tomber dans un des pi√®ges suivants :

* Trop d‚Äôalertes d√©clench√©es, √ßa fait mal aux yeux et √† force on ne les voit plus

![https://media.giphy.com/media/kNwQN4ueScpbaeWtef/giphy.gif](https://media.giphy.com/media/kNwQN4ueScpbaeWtef/giphy.gif)

* Trop de fausse alertes, rend le run perm√©able √† une erreur humaine
* Des alertes qui manquent de pertinences, vont l√† aussi vous faire perdre du temps pr√©cieux lors d‚Äôun troubleshooting

## Quels outils avons-nous choisi ?

### Opsgenie

###### ![OpsGenie Logo](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/OpsGenie.png "OpsGnie")

Pour ces fonctionnalit√©s, ses int√©grations :

* Applications Android, Iphone
* 200 [int√©grations](https://www.atlassian.com/software/opsgenie/integrations)
* Alertes SMS, Mail, appel vocaux, Slack
* Possibilit√© de renommer, reclasser des alertes en fonction de diff√©rents patterns (en pr√©/post traitement)
* Gestion de multiples workflows (escalades en heure ouvr√©es, non ouvr√©es en fonction de patterns)
* Gestion des post-mortem (cr√©ation de channel slack, activit√©s, processus de review)

### StatusPage

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Status page.png)

OpsGenie est cabl√© √† [StatusPage](https://yousign.statuspage.io/), ce qui nous permet entre autres :

* De cr√©er un incident sur notre page de [Status](https://yousign.statuspage.io/) pour pr√©venir nos clients
* Cr√©er un post-mortem afin de respecter nos processus SRE et communiquer aux clients la root-cause ainsi que nos actions permettant de mitiger ou r√©soudre l‚Äôincident

## Gestion du planning d‚Äôastreinte et de RUN

Sur OpsGenie nous avons le planning d‚Äôastreinte, et de run.

Bien entendu ceux-ci sont consultables sur Google Agenda, et via l‚Äôextension Slack en quelques clics.

## Reporting ou l‚Äôart de mesurer la performance

OpsGenie permet de g√©n√©rer des rapports en fonction:

* Des squads
* Des priorit√©s
* De filtres li√©es aux alertes (priorit√©, contenu de l‚Äôalerte, etc.)

Et de b√©n√©ficier des KPI suivantes :

* Nombre d‚Äôalertes, incidents, postmortem
* MTTA
* MTTR
* Escalades
* Etc.

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/KPI.png)

## Onboarding

Nous proposons un cursus de formation en interne sur notre outil de gestion des incidents, mais √©galement des vid√©os pour monter en comp√©tences sur une bonne partie de nos outils. Ce qui participe a r√©duire le temps de r√©solution, et le stress associ√© lors d‚Äôun incident.

## Quels gains sur le moyen terme ?

Le fait de responsabiliser les squads apporte un gain incroyable au quotidien :

* Ils adaptent leurs propres alertes : revue des seuils, conditions des alertes
* Quand une squad rencontre trop souvent la m√™me alerte, elle se concentre sur la diminution de sa fr√©quence (refactoring des alertes, modification du comportement applicatif, am√©lioration des performance, ajout de logs, etc.)
* Reporting facilit√© : on peut savoir quelle team rencontre le plus de probl√®mes, quelle application, quel temps de r√©tablissement, etc.
* Diminution du temps de traitement des alertes, car ce n‚Äôest plus une √©quipe mais un ensemble de squads
* Onboarding facilit√© gr√¢ce √† l‚Äôalerte qui est document√©e

## 6 conseils sur le mindset a avoir lors d‚Äôun incident

* Garder la t√™te froide

![https://media.giphy.com/media/26Ffb2KfjmqtOaKLS/giphy.gif](https://media.giphy.com/media/26Ffb2KfjmqtOaKLS/giphy.gif)

* R√©duire le nombre de personnes dans la room au strict minimum (moins de 6 nous parait pertinent)
* Inclure le management et le customer care √† votre prise de d√©cision, pour prendre des d√©cisions √©clair√©es et communiquer sur l‚Äôincident (ce qui est tout un art).
* D√©rouler une checklist si vous en avez une, √ßa rassure et permet de ne pas oublier certains items
* Cr√©er un post-mortem au plus t√¥t pour que chaque acteur puisse y ajouter ses activit√©s, ses remarques
* Si vous paniquez, demandez de l‚Äôaide, personne ne vous en voudra
* Agir et √©crire sont deux r√¥les diff√©rents, pensez √† avoir un scribe et mieux un incident manager qui s‚Äôoccupera de la communication üôÇ

## Comment mettre en place une gestion des incidents en startup ?

* Adapter la gestion des incidents √† la taille de votre structure, vos attentes produits et tech sont primordiaux üëç
* Rien n‚Äôest pire qu‚Äôun processus qui n‚Äôacquiert pas de l‚Äôadh√©sion aupr√®s des √©quipes et du management. Fixez vous de petits objectifs (environnement de non production par exemple), puis it√©rez sur les niveaux de criticit√© au rythme de la mont√©e en comp√©tences des squads
* Former les Engineering managers √† piloter ce processus de RUN aupr√®s de leurs squads
* Former l‚Äôensemble des collaborateurs tech √† cet √©tat d‚Äôesprit _you build-it, you run it_
* Donner de la visibilit√©, partagez vos victoires et vos √©checs est primordial dans cette d√©marche transverse.

## Les grandes √©tapes

* Choisissez un outil (OpsGenie, PagerDuty, etc.), il y a des tas de benchmarks sur le net
* Cr√©ez un projet pour cr√©er/am√©liorer ce processus de gestion des incidents
* Impliquez les EM, collaborateurs en leur proposant votre vision du workflow
* Prenez en compte leurs remarques
* Impl√©mentez l‚Äôoutil de votre choix
* Impl√©mentez votre processus
* Diffusez-le un maximum
* Formez les squads
* Recueillez le feedback des √©quipes
* Am√©liorez et it√©rez jusqu‚Äô√† que vos KPI correspondent √† vos besoins

## Axes d‚Äôam√©lioration √† venir

* Nous avons design√© un workflow sp√©cifique √† la **gestion** **de** **crise**, et nous aimerions passer √† son ex√©cution
* G√©rer la totalit√© des alertes via nos outils d‚Äô**I**nfrastructure **A**s **C**ode (Terraform, Pulumi), car actuellement seuls 20% des alertes sont auto-provisionn√©s
* Un ‚Äúpermis‚Äù pour faire du run en production (p√©riode probatoire en pair programming, formations sur les outils de troubleshooting, test technique sur une application de d√©mo)
* Mise en place de **SLO** (Service Level Objective)

[**Daniel Castronovo**](https://fr.linkedin.com/in/danielcastronovo)