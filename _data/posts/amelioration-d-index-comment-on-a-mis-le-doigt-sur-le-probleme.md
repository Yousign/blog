---
tags: []
published: true
title: Am√©lioration d'index, comment on a mis le doigt sur le probl√®me ?
excerpt: Nous avions un gros pain concernant le listing de nos proc√©dures en production,
  ainsi que sur la recherche au sein de ces derni√®res. √Ä l'heure o√π ces lignes sont
  √©crites, cela fait maintenant 8 mois que nous avons divis√© par 4, voire 5, le temps
  d'affichage du listing de nos proc√©dures.
coverImage: https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/10-optimization-request@2x.png
date: 2021-12-15T08:00:00Z
authors:
- _data/authors/Kevin Auvinet.md

---
Nous avions un gros pain concernant le listing de nos proc√©dures en production, ainsi que sur la recherche au sein de ces derni√®res.

## Contexte

√Ä l'heure o√π ces lignes sont √©crites, cela fait maintenant 8 mois que nous avons divis√© par 4, voire 5, le temps d'affichage du listing de nos proc√©dures.

M√™me si une premi√®re optimisation avait eu lieu (passage de MariaDb √† PostgreSQL avec refonte des requ√™tes), nous avons pass√© un nouveau seuil et certaines de nos requ√™tes aboutissaient sur le tant redout√© code erreur 504 (Time Out).

Pour corriger cela en limitant au maximum les impacts, le temps allou√©* et sans cr√©er de r√©gressions, nous avons tent√© plusieurs approches avant de trouver la plus adapt√©e. Voici donc comment nous y sommes arriv√©s et les choix qui nous ont guid√©s jusque l√†.

## Strat√©gie et frappe chirurgicale

Outre les remont√©es clients de plus en plus nombreuses, nos diff√©rents dashboards sur nos outils de monitoring comme NewRelic ou Graylog nous alertaient √©galement de la criticit√© de la situation.

Nous avions de plus en plus de transactions longues c√¥t√© NewRelic et de plus en plus de code statut en 500 et/ou 504 cot√© Graylog...

Gr√¢ce √† ces deux outils, nous savions d√©j√† que le probl√®me venait du listing de nos proc√©dures, dont le volume grossissait √† vitesse grand V. Nous avions √©galement un aper√ßu de la requ√™te en cause. Malheureusement, cette requ√™te n'√©tait pas des plus simples et elle variait en fonction des param√®tres pass√©s dans l'URL ...

Nous avons donc r√©alis√© un petit script fait maison pour cibler la cause qui :

* Analysait les logs des requ√™tes dont la dur√©e d√©passait les 2 secondes
* Regroupait les requ√™tes similaires
* Et pour chacune d'elle, affichait son taux d'utilisation et sa dur√©e moyenne.

Ces m√©triques nous ont ainsi permis de pouvoir d√©finir plus facilement une priorisation des requ√™tes √† traiter.

üí° Pour cet article nous mettrons le focus sur la requ√™te principale qui nous a pos√© souci de par sa complexit√© et ses variantes, √† savoir celle du listing de proc√©dures et des recherches de ces derni√®res.

## Apr√®s la strat√©gie, les mains dans le cambouis

Maintenant, que nous avions une estimation des temps de traitement, ainsi que des principales requ√™tes en cause. Nous pouvions ainsi nous focus sur ces derni√®res.

Il √©tait temps de nous retrousser les manches et tenter de solutionner cette probl√©matique de latence, en maximisant le temps investi et sans cr√©er de r√©gression sur les r√©sultats des requ√™tes modifi√©es.

## Place √† l'analyse

La latence d'une requ√™te peut √™tre due √† plusieurs facteurs ; les jointures, l'ordre des clauses, les index, etc... Sans compter bien √©videmment la taille de(s) table(s) utilis√©e(s).

Pour analyser nos requ√™tes, c'est √† dire comprendre au mieux comment elles √©taient interpr√©t√©es par notre moteur PostgreSQL et identifier o√π l'analyse du moteur √©tait la plus lente, nous avons utilis√© l'outil `EXPLAIN ANALYZE` fourni par ce dernier.

<aside> üí° Le r√©sultat de cette analyse peut-√™tre retourn√© au format texte, json ou encore xml : Pratique si le parseur utilis√© demande un format bien particulier !

</aside>

Nous avons ensuite utilis√© un l'outil en ligne [https://tatiyants.com/pev/#/plans/new](https://tatiyants.com/pev/#/plans/new "https://tatiyants.com/pev/#/plans/new") pour avoir une repr√©sentation graphique du r√©sultat. Nous pouvions ainsi voir quels traitements √©taient faits en parall√®le, ceux qui n√©cessitaient le r√©sultat d'un autre, ceux qui prenaient plus de temps, etc...

## Comment solutionner tout √ßa

√Ä partir de ces r√©sultats, nous avons it√©r√© sur plusieurs solutions jusqu'√† trouver la bonne.

Les solutions ci-dessous sont list√©es dans le m√™me ordre que nous les avons essay√©es.

Nous sommes d'accord, pour certains d'entre vous ce n'est s√ªrement pas logique, mais pour nous √ßa l'√©tait √† ce moment-l√† üòÖ (les analyses et le troubleshooting sont souvent issues d'une approche empirique et donc ne se font pas dans un sens logique)

## 1√®re approche - la clause SQL "WITH"

Au vu des r√©sultats et de la complexit√© de notre 1√®re requ√™te, nous avons fait des essais en utilisant la commande `WITH` de SQL.

Elle permet de jouer des requ√™tes en amont de notre `SELECT` et de stocker le r√©sultat au sein de tables temporaires qui peuvent √™tre utilis√©es ensuite dans la requ√™te. (voir requ√™te ci-dessous)

C'est pratique pour limiter les jointures et optimiser au maximum les index d√©finis sur les tables.

    ```sql
        WITH
            temp_table_1 AS (
                SELECT id as table_1_id
                FROM "table_1"
                WHERE name ILIKE '%<value>%'
            ),
            temp_table_2 AS (
                SELECT table_1_id
                FROM "table_2"
                WHERE first_name ILIKE '%<value>%'
                OR  last_name ILIKE '%<value>%'
                OR  phone ILIKE '%<value>%'
                OR  email ILIKE '%<value>%'
            ),
            temp_table_3 AS (
                SELECT table_1_id
                FROM "table_3"
                WHERE name ILIKE '%<value>%'
            ),
            temp_table_2_bis AS (
                SELECT table_1_id
                FROM "table_2"
                WHERE "user" = '<user_id>'
            )
        SELECT t.*
        FROM "table_1" s
        WHERE t.workspace = '<workspace_id>'
        AND t.deleted = FALSE
        AND t.template = FALSE
        AND t.status = 'finished'
        AND (
                EXISTS(SELECT table_1_id FROM temp_table_2_bis WHERE table_1_id = t.id)
            OR  t.creator = '<user_id>'
        )
        AND (
                EXISTS(SELECT table_1_id FROM temp_table_1 WHERE table_1_id = t.id)
            OR  EXISTS(SELECT table_1_id FROM temp_table_2 WHERE table_1_id = t.id)
            OR  EXISTS(SELECT table_1_id FROM temp_table_3 WHERE table_1_id = t.id)
        )
        ORDER BY t.created_at DESC, t.id ASC LIMIT 20;```

L'utilisation de la commande `WITH` nous a permis d'avoir de bons r√©sultats. Lors de nos tests sur un replica de nos tables, pour la m√™me requ√™te r√©√©crite, nous passions d'environ 45 secondes √† seulement 2 secondes !

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Capture_dcran_de_2021-02-05_19-34-25.png)

**Graphique d'analyse effectu√© gr√¢ce aux r√©sultats de la commande `EXPLAIN ANALYZE` de PostgreSQL**

Malgr√© ces r√©sultats encourageants, nous avons d√ª renoncer √† cette solution. En effet, l'utilisation de Doctrine et notamment l'abstraction que nous avions avec l'utilisation du QueryBuilder de Doctrine, nous a contraint √† abandonner cette solution pour la complexit√© qu'elle engendrait.

En effet, le QueryBuilder de Doctrine, ne g√®re pas par d√©faut l'utilisation de la commande `WITH`. Il aurait donc fallu faire h√©riter ou d√©corer la classe `Doctrine\\ORM\\QueryBuilder` , ce qui n'est pas une mince affaire, que ce soit en terme de complexit√©, de maintenance ou d'√©ventuelles r√©gressions.

## 2nde approche - un aplatissement des donn√©es

Suite au postulat pr√©c√©dent, nous nous sommes demand√©s comment limiter au maximum les jointures.

A l'aide des analyses pr√©c√©dentes et en jouant certaines parties ind√©pendamment les unes des autres, nous avons pu constater que les jointures y jouaient pour beaucoup sur la dur√©e du traitement.

Par exemple la requ√™te ci-dessous, mettait en moyenne moins d'une seconde pour avoir un r√©sultat :

    SELECT id
    FROM "table_2"
    WHERE name ILIKE '%<value>%';

Idem, pour la requ√™te ci-dessous :

    SELECT id
    FROM "table_2"
    WHERE first_name ILIKE '%<value>%'
    OR  last_name ILIKE '%<value>%'
    OR  phone ILIKE '%<value>%'
    OR  email ILIKE '%<value>%';

Par contre, ces deux requ√™tes ensemble avec une jointure et des conditions `WHERE ... OR ...` comme ci-dessous dedans faisait exploser le temps √† plus de 60 secondes.

    SELECT t.*
    FROM "table_1" s
    WHERE t.workspace = '<workspaceIri>'
    AND t.deleted = FALSE
    AND t.template = FALSE
    AND t.status = '<status>'
    AND (
        EXISTS (
            SELECT s1.id
            FROM "table_2" s1
            WHERE s1.signature_id = t.id
            AND s1."user" = '<userIri>'
        )
        OR t.creator = '<userIri>'
    )
    AND (
        EXISTS (
            SELECT s2.id
            FROM "table_1" s2
            WHERE s2.id = t.id
            AND s2.name ILIKE '%<value>%'
        )
        OR EXISTS (
            SELECT s3.id
            FROM "table_2" s3
            WHERE s3.signature_id = t.id
            AND (
                    s3.first_name ILIKE '%<value>%'
                OR  s3.last_name ILIKE '%<value>%'
                OR  s3.phone ILIKE '%<value>%'
                OR  s3.email ILIKE '%<value>%'))
       OR EXISTS (
            SELECT s4.id
            FROM "table_3" s4
            WHERE s4.signature_id = t.id
            AND s4.name ILIKE '%<value>%'
        )
    )
    ORDER BY t.created_at DESC, t.id ASC LIMIT 20;

Du coup, on s'est dit, pourquoi ne pas tout mettre √† plat ?

Afin de tester un potentiel gain avec cette m√©thode, nous avons cr√©√©e une table sur notre replica. Cette table contient seulement les donn√©es agr√©g√©es n√©cessaires √† la requ√™te et issues de 4 tables diff√©rentes.

Nous y avons ajout√© les index n√©cessaires permettant de r√©pondre aux diff√©rents besoins utilisateurs.

Cette technique nous a permis d'avoir un gain de performance √©norme ! Certaines requ√™tes passaient de plusieurs dizaines de secondes √† moins d'une milliseconde malgr√© la volum√©trie de la table (plusieurs dizaines de millions d'entr√©es) !

Cependant, malgr√© cette nette am√©lioration, cette solution amenait une probl√©matique sur laquelle nous n'avions que tr√®s peu de recul √† ce moment l√† : comment mettre √† jour cette table dans un d√©lai raisonnable ? On aurait pu mettre en place des Triggers, mais nous n'avions aucune connaissance sur la gestion de la concurrence qui en d√©coulait, et au vu du timing assez serr√©, nous avons fait le choix de ne garder cette solution qu'en cas de dernier recours. En effet, nous souhaitons dans la mesure du possible dans nos impl√©mentations ne pas ajouter de complexit√© qui pourrait √™tre √©vit√©e (le co√ªt de maintenance et de dilution de la comp√©tence est souvent important, sans parler du risque d'avoir des edge cases qui n'ont pas √©t√© vus √† la conception).

## 3√®me et derni√®re approche - les index

Comme indiqu√© au dessus, nous aurions pu nous pencher sur les index en premier. Nous ne l'avons pas fait, car nous avions d√©j√† fait ce travail quelques mois auparavant, lorsque nous sommes pass√©s d'un MariaDB √† un PostgreSQL en terme de base de donn√©es.

Du coup, nous avons pens√© √† ce moment l√† que le probl√®me majeur ne pas pouvait venir de l√†, surtout connaissant l'ensemble du travail fournis et les r√©sultats √† l'√©poque (la confiance n'emp√™che pas la v√©rification, vieille adage qui aurait pu porter ses fruits ici).

Cependant, nous √©tions arriv√©s √† un stade o√π il nous fallait des r√©sultats rapidement. L'insatisfaction client ne cessait d'augmenter, et les probl√®mes de s'accumuler.

Travaillant sur un r√©plica en mode sandbox, on s'est dit "_Bon, pourquoi ne pas essayer les index, de toutes mani√®res au point o√π l'on en est, au moins on sera fix√© !_". (Merci √† la team SRE pour √ßa d'ailleurs)

On a donc regard√© le code, la structure des tables (dont la principale qui g√®re les proc√©dures), et on a vu un premier truc √©trange... L'index de recherche d√©fini au niveau d'une table ne matchait pas vraiment le code. Non pas que les champs choisis √©taient mauvais ou incorrects, mais ils n'√©taient pas du tout d√©finis dans le bon ordre, et donc ne matchaient avec quasiment aucune de nos conditions ü§î ...

Sur le clone de la base de donn√©es, nous avons d√©cid√© de supprimer l'index en place, pour en recr√©er un autre plus coh√©rent avec notre code. Nous avons ensuite lanc√© la requ√™te la plus longue que nous ayons identifi√©s pour voir la diff√©rence. R√©sultat : nous sommes pass√©s pour certaines requ√™tes d'un timeout √† un r√©sultat en 7 ou 8 secondes üí™ !

Suite √† cette nette am√©lioration, nous avons encore r√©ussi √† am√©liorer l√©g√®rement le r√©sultat en r√©organisant plus intelligemment nos conditions dans la clause `WHERE` en fonction des param√®tres de recherche les plus r√©currents, mais √©galement en fonction de leur type. Un index sur un champs de type `integer` est plus performant qu'un index sur un champs de type `text`, par exemple.

Ci-dessous, un aper√ßu visuel du gain de performance que nous avons obtenu :

üí° les graphes proviennent de notre environnement de staging, mais les gains ont √©t√© les m√™mes sur la prod. Nous n'avons malheureusement pas pris de captures √† l'√©poque ...

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Screen2.png)

**Gain au niveau de la route GET /procedures**

![](https://ys-storage-public-blogtech-content-bucket.s3.eu-west-3.amazonaws.com/Screen1.png)

**Gain de performance au niveau de la base de donn√©es**

## Que peut-on en dire et qu'a t-on appris ?

On ne va pas se mentir, le sujet n'√©tait pas des plus sexy de prime abord. Mettre le nez dans des requ√™tes SQL assez complexes, appr√©hender le code g√©n√©rique cot√© backend qui permettait de g√©n√©rer ces derni√®res et tenter de comprendre tant bien que mal le charabia analytique que nous retournait la commande `EXPLAIN ANALYZE` n'a pas toujours √©t√© une partie de plaisir.

N√©anmoins, travailler sur ce sujet a √©t√© tr√®s instructif, tant au niveau de l'analyse d'une requ√™te SQL par le moteur, qu'au niveau de l'anticipation des probl√®mes de volum√©trie qui peuvent survenir, comme nous en avons eu.

Les outils que nous avions mis en place tels que Graylog, NewRelic ou encore PgHero, nous ont √©t√© d'une grande d'aide. Sans compter √©galement ceux trouv√©s en ligne tels que [https://explain.depesz.com/](https://explain.depesz.com/ "https://explain.depesz.com/") , ou encore [https://tatiyants.com/](https://tatiyants.com/ "https://tatiyants.com/"), pour nous aider √† comprendre certaines analyses de requ√™tes. Ils nous ont permis de voir les am√©liorations √† chaque it√©ration, mais √©galement de pouvoir monitorer nos requ√™tes et d√©celer celles anormalement longues (m√™me encore maintenant).

Nous sommes conscients que la solution retenue au final n'est pas la meilleure. Certes, nous avons obtenu un gros gain de performance, mais certaines de nos requ√™tes retournent encore un r√©sultat au bout de plusieurs secondes, voir dizaines de secondes parfois... N√©anmoins, avant nous en avions beaucoup et l'impact pour certains clients n'√©tait pas acceptable, d'autant maintenant ce sont des cas √† la marge qui surviennent dans des contextes tr√®s limit√©s.

Pourquoi nous avons d√©cid√© de nous arr√™ter l√†? C'est le contexte, qui nous a d√©cid√© √† ne pas aller plus loin dans l'optimisation. La prochaine version √©tait d√©j√† en pr√©paration, nous nous sommes dit que les r√©sultats obtenus √©taient plus qu'acceptables et nous n'avions plus de clients g√™n√©s par ces lenteurs. Cependant, nous avons quand m√™me pu remonter certaines probl√©matiques et solutions √† l'√©quipe travaillant sur la version suivante pour qu'ils puissent anticiper ce genre de probl√®me.

Par ailleurs, nous avons conscience que faire de la recherche de donn√©es au sein d'une base de donn√©es est possible, mais n'est pas optimal. Nous aurions pu construire une table d√©di√©e √† la recherche en y agr√©geant des donn√©es, mais une solution telle qu'un Elasticsearch ou un Algolia est pr√©f√©rable sur le long terme. Apr√®s, comme toutes solutions techniques, il est pr√©f√©rable de peser le pour et le contre, car de telles solutions, malgr√© le gain qu'elles apportent, peuvent √™tre lourdes √† mettre en ≈ìuvre et/ou co√ªteuses !

_*Une nouvelle version √©tait en d√©veloppement_

[**Kevin Auvinet**](https://www.linkedin.com/in/kevin-auvinet-1614493a/)